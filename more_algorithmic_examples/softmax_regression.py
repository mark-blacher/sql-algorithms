import numpy as np
import time


# this file contains a gradient descent implementation
# for softmax regression in Python

def softmax(XW):
    cols = XW.shape[1]
    e_x = np.exp(XW - np.repeat(np.amax(XW, axis=1)[:, np.newaxis], cols, axis=1))
    repeated_row_sums = np.repeat(np.sum(e_x, axis=1)[:, np.newaxis], cols, axis=1)
    return e_x / repeated_row_sums + 2.220446049250313e-16


def gradient(W, X, Y):
    sm = softmax(X.dot(W))
    return -np.dot(X.T, Y - sm) + W


# batch gradient descent
def gradient_descent(X, Y, iterations, alpha):
    W = np.zeros((X.shape[1], Y.shape[1]))
    for i in range(iterations):
        g = gradient(W, X, Y)
        W = W - alpha * g
    return W


# predict classes of samples in X, use weights W
def predict(X, W):
    p = softmax(X.dot(W))
    return np.argmax(p, axis=1)


if __name__ == "__main__":
    # shuffled Iris dataset
    iris = [
        [5.8, 4.0, 1.2, 0.2, 0], [5.1, 2.5, 3.0, 1.1, 1], [6.6, 3.0, 4.4, 1.4, 1], [5.4, 3.9, 1.3, 0.4, 0],
        [7.9, 3.8, 6.4, 2.0, 2], [6.3, 3.3, 4.7, 1.6, 1], [6.9, 3.1, 5.1, 2.3, 2], [5.1, 3.8, 1.9, 0.4, 0],
        [4.7, 3.2, 1.6, 0.2, 0], [6.9, 3.2, 5.7, 2.3, 2], [5.6, 2.7, 4.2, 1.3, 1], [5.4, 3.9, 1.7, 0.4, 0],
        [7.1, 3.0, 5.9, 2.1, 2], [6.4, 3.2, 4.5, 1.5, 1], [6.0, 2.9, 4.5, 1.5, 1], [4.4, 3.2, 1.3, 0.2, 0],
        [5.8, 2.6, 4.0, 1.2, 1], [5.6, 3.0, 4.5, 1.5, 1], [5.4, 3.4, 1.5, 0.4, 0], [5.0, 3.2, 1.2, 0.2, 0],
        [5.5, 2.6, 4.4, 1.2, 1], [5.4, 3.0, 4.5, 1.5, 1], [6.7, 3.0, 5.0, 1.7, 1], [5.0, 3.5, 1.3, 0.3, 0],
        [7.2, 3.2, 6.0, 1.8, 2], [5.7, 2.8, 4.1, 1.3, 1], [5.5, 4.2, 1.4, 0.2, 0], [5.1, 3.8, 1.5, 0.3, 0],
        [6.1, 2.8, 4.7, 1.2, 1], [6.3, 2.5, 5.0, 1.9, 2], [6.1, 3.0, 4.6, 1.4, 1], [7.7, 3.0, 6.1, 2.3, 2],
        [5.6, 2.5, 3.9, 1.1, 1], [6.4, 2.8, 5.6, 2.1, 2], [5.8, 2.8, 5.1, 2.4, 2], [5.3, 3.7, 1.5, 0.2, 0],
        [5.5, 2.3, 4.0, 1.3, 1], [5.2, 3.4, 1.4, 0.2, 0], [6.5, 2.8, 4.6, 1.5, 1], [6.7, 2.5, 5.8, 1.8, 2],
        [6.8, 3.0, 5.5, 2.1, 2], [5.1, 3.5, 1.4, 0.3, 0], [6.0, 2.2, 5.0, 1.5, 2], [6.3, 2.9, 5.6, 1.8, 2],
        [6.6, 2.9, 4.6, 1.3, 1], [7.7, 2.6, 6.9, 2.3, 2], [5.7, 3.8, 1.7, 0.3, 0], [5.0, 3.6, 1.4, 0.2, 0],
        [4.8, 3.0, 1.4, 0.3, 0], [5.2, 2.7, 3.9, 1.4, 1], [5.1, 3.4, 1.5, 0.2, 0], [5.5, 3.5, 1.3, 0.2, 0],
        [7.7, 3.8, 6.7, 2.2, 2], [6.9, 3.1, 5.4, 2.1, 2], [7.3, 2.9, 6.3, 1.8, 2], [6.4, 2.8, 5.6, 2.2, 2],
        [6.2, 2.8, 4.8, 1.8, 2], [6.0, 3.4, 4.5, 1.6, 1], [7.7, 2.8, 6.7, 2.0, 2], [5.7, 3.0, 4.2, 1.2, 1],
        [4.8, 3.4, 1.6, 0.2, 0], [5.7, 2.5, 5.0, 2.0, 2], [6.3, 2.7, 4.9, 1.8, 2], [4.8, 3.0, 1.4, 0.1, 0],
        [4.7, 3.2, 1.3, 0.2, 0], [6.5, 3.0, 5.8, 2.2, 2], [4.6, 3.4, 1.4, 0.3, 0], [6.1, 3.0, 4.9, 1.8, 2],
        [6.5, 3.2, 5.1, 2.0, 2], [6.7, 3.1, 4.4, 1.4, 1], [5.7, 2.8, 4.5, 1.3, 1], [6.7, 3.3, 5.7, 2.5, 2],
        [6.0, 3.0, 4.8, 1.8, 2], [5.1, 3.8, 1.6, 0.2, 0], [6.0, 2.2, 4.0, 1.0, 1], [6.4, 2.9, 4.3, 1.3, 1],
        [6.5, 3.0, 5.5, 1.8, 2], [5.0, 2.3, 3.3, 1.0, 1], [6.3, 3.3, 6.0, 2.5, 2], [5.5, 2.5, 4.0, 1.3, 1],
        [5.4, 3.7, 1.5, 0.2, 0], [4.9, 3.1, 1.5, 0.2, 0], [5.2, 4.1, 1.5, 0.1, 0], [6.7, 3.3, 5.7, 2.1, 2],
        [4.4, 3.0, 1.3, 0.2, 0], [6.0, 2.7, 5.1, 1.6, 1], [6.4, 2.7, 5.3, 1.9, 2], [5.9, 3.0, 5.1, 1.8, 2],
        [5.2, 3.5, 1.5, 0.2, 0], [5.1, 3.3, 1.7, 0.5, 0], [5.8, 2.7, 4.1, 1.0, 1], [4.9, 3.1, 1.5, 0.1, 0],
        [7.4, 2.8, 6.1, 1.9, 2], [6.2, 2.9, 4.3, 1.3, 1], [7.6, 3.0, 6.6, 2.1, 2], [6.7, 3.0, 5.2, 2.3, 2],
        [6.3, 2.3, 4.4, 1.3, 1], [6.2, 3.4, 5.4, 2.3, 2], [7.2, 3.6, 6.1, 2.5, 2], [5.6, 2.9, 3.6, 1.3, 1],
        [5.7, 4.4, 1.5, 0.4, 0], [5.8, 2.7, 3.9, 1.2, 1], [4.5, 2.3, 1.3, 0.3, 0], [5.5, 2.4, 3.8, 1.1, 1],
        [6.9, 3.1, 4.9, 1.5, 1], [5.0, 3.4, 1.6, 0.4, 0], [6.8, 2.8, 4.8, 1.4, 1], [5.0, 3.5, 1.6, 0.6, 0],
        [4.8, 3.4, 1.9, 0.2, 0], [6.3, 3.4, 5.6, 2.4, 2], [5.6, 2.8, 4.9, 2.0, 2], [6.8, 3.2, 5.9, 2.3, 2],
        [5.0, 3.3, 1.4, 0.2, 0], [5.1, 3.7, 1.5, 0.4, 0], [5.9, 3.2, 4.8, 1.8, 1], [4.6, 3.1, 1.5, 0.2, 0],
        [5.8, 2.7, 5.1, 1.9, 2], [4.8, 3.1, 1.6, 0.2, 0], [6.5, 3.0, 5.2, 2.0, 2], [4.9, 2.5, 4.5, 1.7, 2],
        [4.6, 3.2, 1.4, 0.2, 0], [6.4, 3.2, 5.3, 2.3, 2], [4.3, 3.0, 1.1, 0.1, 0], [5.6, 3.0, 4.1, 1.3, 1],
        [4.4, 2.9, 1.4, 0.2, 0], [5.5, 2.4, 3.7, 1.0, 1], [5.0, 2.0, 3.5, 1.0, 1], [5.1, 3.5, 1.4, 0.2, 0],
        [4.9, 3.0, 1.4, 0.2, 0], [4.9, 2.4, 3.3, 1.0, 1], [4.6, 3.6, 1.0, 0.2, 0], [5.9, 3.0, 4.2, 1.5, 1],
        [6.1, 2.9, 4.7, 1.4, 1], [5.0, 3.4, 1.5, 0.2, 0], [6.7, 3.1, 4.7, 1.5, 1], [5.7, 2.9, 4.2, 1.3, 1],
        [6.2, 2.2, 4.5, 1.5, 1], [7.0, 3.2, 4.7, 1.4, 1], [5.8, 2.7, 5.1, 1.9, 2], [5.4, 3.4, 1.7, 0.2, 0],
        [5.0, 3.0, 1.6, 0.2, 0], [6.1, 2.6, 5.6, 1.4, 2], [6.1, 2.8, 4.0, 1.3, 1], [7.2, 3.0, 5.8, 1.6, 2],
        [5.7, 2.6, 3.5, 1.0, 1], [6.3, 2.8, 5.1, 1.5, 2], [6.4, 3.1, 5.5, 1.8, 2], [6.3, 2.5, 4.9, 1.5, 1],
        [6.7, 3.1, 5.6, 2.4, 2], [4.9, 3.6, 1.4, 0.1, 0]
    ]

    iris_data = np.array(iris)
    X = iris_data[:, :-1]
    y = iris_data[:, -1].astype(np.int64)

    # add column of ones (for intercept)
    X = np.column_stack((X, np.ones(X.shape[0])))

    # one-hot encoding for classification
    amount_classes = len(np.unique(y))
    y_one_hot = np.eye(amount_classes)[y]
    Y = y_one_hot

    t0 = time.time()
    W = gradient_descent(X, Y, iterations=2000, alpha=0.001)
    print("seconds: ", time.time() - t0)
    print("W:", W.T)
    preds = predict(X, W)
    accuracy = sum(preds == y) / float(len(y))
    print("train accuracy: ", accuracy)
